
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ITP-459 Generative AI and Applied Machine Learning for Natural Language Processing (NLP)</title>
    <style>
        body {
            font-family: 'SF Hello', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #4d4d4d; /* #333 Dark gray background */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh; /* Full viewport height */
        }
        table {
            width: 40%;
            border-collapse: collapse;
        }
        th, td {
            border: 2px solid black;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }

        
        .content-wrapper {
          width: 80%; /* or any other percentage or fixed width */
          background-color: #e0e0e0; /* #ccc Light gray background */
          margin: 20px;
          padding: 20px;
          border: 3px solid #aaa; /* Lighter gray border */
          box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1); /* Optional: Adds shadow for depth */
          border-radius: 20px; /* Optional: Rounds the corners */
}
        
    </style>
</head>
<body>
    <div class="content-wrapper">
    <br><br>
    <h1>ITP-459 Generative AI and Applied Machine Learning for Natural Language Processing (NLP)</h1>
    <h2>University of Southern California (USC), Viterbi School of Engineering </h2>
    <p style="line-height: 1.5;"><strong>Units:</strong>4, <strong>Term:</strong> Spring 2024, <strong>Prerequisite(s):</strong> ITP 359<br>
       <strong>Time:</strong> Mon 6-9:20PM, <strong>Location:</strong> KAP 144</p>
    <h2>Instructor Infromation</h2>
    <h3><strong>Instructor:</strong> <a href="https://www.linkedin.com/in/allenbolourchi/">Allen Bolourchi</a></h3>
       <p style="line-height: 1.5;"> <strong>Adjunct Professor of Generative AI and NLP at USC</strong><br>
        <strong>Founder of <a href="https://www.crystalytic.ai/">Crystalytic.AI</a> </strong></p>
<img src="https://static.wixstatic.com/media/1ea898_97bf6eb77cfc4cf183cb64ff74cc81c8~mv2.jpg/v1/fill/w_439,h_498,al_c,q_80,usm_0.66_1.00_0.01,enc_auto/1ea898_97bf6eb77cfc4cf183cb64ff74cc81c8~mv2.jpg" alt="Instructor Image" style="width:50%;max-width:280px;height:auto;">
<br><br>
       <strong>Office Hours:</strong> Tuesdays 6 PM-8 PM by appointment only.</p>
    <h2>Course Assistants</h2>
    <table>
        <tr>
            <th>Course Assistant</th>
            <th>Mode</th>
            <th>Day and Time</th>
            <th>LinkedIn</th>
        </tr>
        <tr>
            <td>Gaurav Tadkapally</td>
            <td>In Person + Online</td>
            <td>Monday 11:00am - 12:00pm</td>
             <td>...</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>Online</td>
            <td>Thursday 02:00pm - 03:00pm</td>
            <td>...</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>In Person + Online</td>
            <td>Friday 12:30pm - 01:30pm</td>
            <td>...</td>
        </tr>
    </table>
    <h2>Course Description</h2>
    <p style="line-height: 1.5;">Learn the state-of-the-art technology in Artificial Intelligence, including the latest AI tools and algorithms in Natural Language Processing (NLP), Generative AI, and models such as GPT/BERT, along with Hugging Face. <br><br>
You will explore the fundamentals of NLP and discover which technologies and products have been developed using NLP and Generative AI for text. The course covers how to utilize pre-trained Large Language Models (LLMs) and their APIs, fine-tune LLMs, and retrain LLMs.<br></p>

    <h2>Course Schedule: A Weekly Breakdown</h2>
    <table>
        <tr>
            <th>WeeklyTopics and Details</th>
            <th>WeeklyTopics and Details</th>
        </tr>
<tr><td><strong>Week 1: Introduction to NLP and AI</strong><ul><li>Course Overview</li><li>Historical Evolution of AI and NLP</li><li>Key Concepts in Machine Learning and NLP</li><li>Overview of NLP Applications in Various Domains</li><li>Basic Text Processing and Language Understanding</li><li>Challenges and Limitations in NLP</li></ul></td><td><strong>Week 9: Advanced Topics in Machine Learning and NLP</strong><ul><li>Deep Transfer Learning in NLP</li><li>Strategies for Addressing Data Imbalance</li><li>Model Interpretability and Explainability in NLP</li><li>Advanced Optimization Techniques in NLP</li><li>Utilizing Pre-Trained NLP Models</li><li>Case Studies of Advanced ML in NLP</li><li>Retrieval-Augmented Generation</li></ul></td></tr>
<tr><td><strong>Week 2: Text Cleaning and Preprocessing</strong><ul><li>Techniques for Noise Reduction</li><li>Text Normalization and Tokenization</li><li>Lemmatization and Stemming</li><li>Co-occurrence Matrix in Text Analysis</li><li>Feature Extraction from Text</li><li>Regular Expressions in Text Processing</li><li>Basic Overview of Word Embeddings</li><li>Overview of python libraries such as NLTK, Spacy, regex etc. </li></ul></td><td><strong>Week 10: Named Entity Recognition, Information Retrieval and Search</strong><ul><li>Advanced Techniques in NER</li><li>Contextual NER and Its Applications</li><li>Fundamentals of Information Retrieval</li><li>Deep Dive into TF-IDF and Co-occurrence Matrix</li><li>Search Engines and Indexing Techniques</li><li>Evaluation Metrics in Information Retrieval</li><li>Case Studies and Real-World Applications</li></ul></td></tr>
<tr><td><strong>Week 3: Fundamentals of Machine Learning for NLP</strong><ul><li>Supervised Learning and Unsupervised Learning - Key Algorithms for NLP</li><li>Evaluation Metrics for NLP Models</li><li>Training, Validation, and Test Sets in Model Development</li><li>Overfitting and Underfitting in NLP</li><li>Cross-Validation Techniques</li><li>Introduction to Python ML Libraries</li></ul></td><td><strong>Week 11: Advanced Machine Translation and Summarization</strong><ul><li>Advanced Techniques in Machine Translation</li><li>Handling Low-Resource Languages in (Machine Tranlsation) MT</li><li>Text Summarization</li><li>Extractive vs. Abstractive Summarization</li><li>Challenges in Summarization</li><li>Evaluation of Summarization Techniques</li><li>Current Trends in MT and Summarization</li></ul></td></tr>
<tr><td><strong>Week 4: Neural Networks and Deep Learning in NLP</strong><ul><li>Activation Functions and Network Topologies</li><li>Backpropagation and Gradient Descent</li><li>CNNs and RNNs for NLP</li><li>Advanced RNNs: LSTM and GRU</li><li>Sequence Modeling in NLP</li><li>Challenges in Deep Learning for NLP</li><li>Case Studies in Deep Learning for NLP</li></ul></td><td><strong>Week 12: Speech Processing and Conversational AI</strong><ul><li>Basics of Speech Recognition</li><li>Challenges in Automatic Speech Recognition (ASR)</li><li>Design and Development of Conversational Agents</li><li>Evaluating Dialogue Systems in Conversational AI</li><li>Multimodal Interaction in Conversational AI</li><li>Natural Language Understanding in Conversational AI</li><li>Case Studies in Speech Processing and Conversational AI</li></ul></td></tr>
<tr><td><strong>Week 5: Transformer Models and Attention Mechanisms</strong><ul><li>Understanding the Transformer Architecture</li><li>Concepts of Self-Attention and Positional Encoding</li><li>Overview of BERT, GPT, and Transformer Variants</li><li>Applications of Transformer Models in NLP</li><li>Training Transformer Models for NLP Tasks</li><li>Challenges and Solutions with Transformer Models</li></ul></td><td><strong>Week 13: Generative AI, Prodcuts, Techniques, APIs and Ethical Considerations</strong><ul><li>Introduction to Generative Models in NLP</li><li>Applications and Challenges of Generative AI</li><li>Ethical Considerations, Data Privacy and Governance in AI</li><li>NLP APIs and Their Practical Uses</li><li>Prompt Engineering for LLMs</li><li>Busineess Intelligence, Marketing, Analytics and Brand Analysis use cases</li><li>Introduction to Product Management and Business Considerations</li></ul></td></tr>
<tr><td><strong>Week 6: Syntax, Parsing, Word Embeddings, and POS Tagging</strong><ul><li>Syntax in Natural Language Processing</li><li>Dependency and Constituency Parsing</li><li>Deep Dive into Word Embeddings</li><li>Word2Vec, GloVe, and FastText Embeddings</li><li>Using Embeddings in NLP Tasks</li><li>Part-of-Speech (POS) Tagging: Importance, Methods, and Tools</li><li>Practical Parsing, Embedding, and POS Tagging Techniques</li><li>Vector Database</li></ul></td><td><strong>Week 14: Fine-Tuning LLMs, Hugging Face, LangChain and RAG</strong><ul><li>Introduction to Fine-Tuning Large Language Models (ChatGPT, Llama etc)</li><li>Overview and Practical Use of Hugging Face in NLP Projects</li><li>Utilizing LangChain and Llama for Customized Language Models</li><li>Best Practices in Fine-Tuning LLMs</li><li>Challenges and Solutions in Fine-Tuning Language Models</li><li>Case Studies and Applications of Fine-Tuned LLMs</li><li>Architecture of Fine-Tuned Models</li></ul></td></tr>
<tr><td><strong>Week 7: Semantic Analysis, Language Models, and Question Answering</strong><ul><li>Semantic Role Labeling (SRL)</li><li>Knowledge Graphs in Semantic Analysis</li><li>Advances in Contextual Embeddings</li><li>Overview of Language Models in NLP </li><li>Introduction to Question Answering System and Utilizing Language Models</li><li>Challenges in QA and Semantic Analysis</li><li>Word Sense Disambiguation Techniques</li></ul></td><td><strong>Week 15: Course Review, Future Trends, and Project Presentations + Final Exam</strong><ul><li>Recap of Key NLP and Generative AI Concepts</li><li>Discussion on the Future Trends in NLP and Generative AI</li><li>Student Project Presentations</li><li>Feedback and Review of Projects</li><li>Resources for Advanced Learning</li><li>Closing Remarks and Course Evaluation</li><ul></td></tr>
<tr><td><strong>Week 8: Text Classification and Machine Translation + Midterm Exam</strong><ul><li>Fundamentals of Text Classification</li><li>Techniques and Algorithms for Classification</li><li>Introduction to Machine Translation</li><li>Neural Machine Translation (NMT) models</li><li>Challenges and Evaluation Metrics for MT</li><li>Practical Implementation of MT Systems</li></ul></td></tr>
    </table>
        <h2>Technological Proficiency</h2>
    <p>Familiarity with Google Colab and Python is necessary. If you haven’t used them, familiarize yourself with Google Colab and set it up. We will teach you the rest of the python packages in the classroom.<br>
       <a href="https://colab.research.google.com/">Google Colab</a></p>
</div>
</body>
</html>
