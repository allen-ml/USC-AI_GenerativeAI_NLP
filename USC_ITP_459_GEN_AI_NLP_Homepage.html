
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ITP-459 Generative AI and Applied Machine Learning for Natural Language Processing (NLP)</title>
    <style>
        body {
            font-family: 'SF Hello', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #4d4d4d; /* #333 Dark gray background */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh; /* Full viewport height */
        }
        table {
            width: 40%;
            border-collapse: collapse;
        }
        th, td {
            border: 2px solid black;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }

        
        .content-wrapper {
          width: 80%; /* or any other percentage or fixed width */
          background-color: #e0e0e0; /* #ccc Light gray background */
          margin: 20px;
          padding: 20px;
          border: 3px solid #aaa; /* Lighter gray border */
          box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1); /* Optional: Adds shadow for depth */
          border-radius: 20px; /* Optional: Rounds the corners */
}
        
    </style>
</head>
<body>
    <div class="content-wrapper">
    <br><br>
    <h1>ITP-459 Generative AI and Applied Machine Learning for Natural Language Processing (NLP)</h1>
    <h2>University of Southern California (USC), Viterbi School of Engineering </h2>
    <p style="line-height: 1.5;"><strong>Units:</strong>4, <strong>Term:</strong> Spring 2024, <strong>Prerequisite(s):</strong> ITP 359<br>
       <strong>Time:</strong> Mon 6-9:20PM, <strong>Location:</strong> KAP 144</p>
    <h2>Instructor Infromation</h2>
    <h3><strong>Instructor:</strong> <a href="https://www.linkedin.com/in/allenbolourchi/">Allen Bolourchi</a></h3>
       <p style="line-height: 1.5;"> <strong>Adjunct Professor of Generative AI and NLP at USC</strong><br>
        <strong>Founder of <a href="https://www.crystalytic.ai/">Crystalytic.AI</a> </strong></p>
<img src="https://static.wixstatic.com/media/1ea898_97bf6eb77cfc4cf183cb64ff74cc81c8~mv2.jpg/v1/fill/w_439,h_498,al_c,q_80,usm_0.66_1.00_0.01,enc_auto/1ea898_97bf6eb77cfc4cf183cb64ff74cc81c8~mv2.jpg" alt="Instructor Image" style="width:50%;max-width:280px;height:auto;">
<br><br>
       <strong>Office Hours:</strong> Tuesdays 6 PM-8 PM by appointment only.</p>
    <h2>Course Assistants</h2>
    <table>
        <tr>
            <th>Course Assistant</th>
            <th>Mode</th>
            <th>Day and Time</th>
            <th>LinkedIn</th>
        </tr>
        <tr>
            <td>Gaurav Tadkapally</td>
            <td>In Person + Online</td>
            <td>Monday 11:00am - 12:00pm</td>
             <td>...</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>Online</td>
            <td>Thursday 02:00pm - 03:00pm</td>
            <td>...</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>In Person + Online</td>
            <td>Friday 12:30pm - 01:30pm</td>
            <td>...</td>
        </tr>
    </table>
    <h2>Course Description</h2>
    <p style="line-height: 1.5;">Learn the state-of-the-art technology in Artificial Intelligence, including the latest AI tools and algorithms in Natural Language Processing (NLP), Generative AI, and models such as GPT/BERT, along with Hugging Face. <br><br>
You will explore the fundamentals of NLP and discover which technologies and products have been developed using NLP and Generative AI for text. The course covers how to utilize pre-trained Large Language Models (LLMs) and their APIs, fine-tune LLMs, and retrain LLMs.<br></p>

    <h2>Course Schedule: A Weekly Breakdown</h2>
    <table>
        <tr>
            <th>WeeklyTopics and Details</th>
            <th>WeeklyTopics and Details</th>
        </tr>
<tr><td><strong>Week 1: Introduction to NLP and AI</strong><ul><li>Course Overview</li><li>Historical Evolution of AI and NLP</li><li>Key Concepts in Machine Learning and NLP</li><li>Overview of NLP Applications in Various Domains</li><li>Basic Text Processing and Language Understanding</li><li>Challenges and Limitations in NLP</li></ul></td><td><strong>Week 9: Advanced Topics in Machine Learning and NLP</strong><ul><li>Deep Transfer Learning in NLP</li><li>Strategies for Addressing Data Imbalance</li><li>Model Interpretability and Explainability in NLP</li><li>Advanced Optimization Techniques in NLP</li><li>Utilizing Pre-Trained NLP Models</li><li>Case Studies of Advanced ML in NLP</li><li>Retrieval-Augmented Generation</li></ul></td></tr>
<tr><td><strong>Week 2: Text Cleaning and Preprocessing</strong><ul><li>Techniques for Noise Reduction</li><li>Text Normalization and Tokenization</li><li>Lemmatization and Stemming</li><li>Co-occurrence Matrix in Text Analysis</li><li>Feature Extraction from Text</li><li>Regular Expressions in Text Processing</li><li>Basic Overview of Word Embeddings</li><li>Overview of python libraries such as NLTK, Spacy, regex etc. </li></ul></td><td><strong>Week 10: Named Entity Recognition, Information Retrieval and Search</strong><ul><li>Advanced Techniques in NER</li><li>Contextual NER and Its Applications</li><li>Fundamentals of Information Retrieval</li><li>Deep Dive into TF-IDF and Co-occurrence Matrix</li><li>Search Engines and Indexing Techniques</li><li>Evaluation Metrics in Information Retrieval</li><li>Case Studies and Real-World Applications</li></ul></td></tr>
<tr><td><strong>Week 3: Fundamentals of Machine Learning for NLP</strong><ul><li>Supervised Learning and Unsupervised Learning - Key Algorithms for NLP</li><li>Evaluation Metrics for NLP Models</li><li>Training, Validation, and Test Sets in Model Development</li><li>Overfitting and Underfitting in NLP</li><li>Cross-Validation Techniques</li><li>Introduction to Python ML Libraries</li></ul></td><td><strong>Week 11: Advanced Machine Translation and Summarization</strong><ul><li>Advanced Techniques in Machine Translation</li><li>Handling Low-Resource Languages in (Machine Tranlsation) MT</li><li>Text Summarization</li><li>Extractive vs. Abstractive Summarization</li><li>Challenges in Summarization</li><li>Evaluation of Summarization Techniques</li><li>Current Trends in MT and Summarization</li></ul></td></tr>
<tr><td><strong>Week 4: Neural Networks and Deep Learning in NLP</strong><ul><li>Activation Functions and Network Topologies</li><li>Backpropagation and Gradient Descent</li><li>CNNs and RNNs for NLP</li><li>Advanced RNNs: LSTM and GRU</li><li>Sequence Modeling in NLP</li><li>Challenges in Deep Learning for NLP</li><li>Case Studies in Deep Learning for NLP</li></ul></td><td><strong>Week 12: Speech Processing and Conversational AI</strong><ul><li>Basics of Speech Recognition</li><li>Challenges in Automatic Speech Recognition (ASR)</li><li>Design and Development of Conversational Agents</li><li>Evaluating Dialogue Systems in Conversational AI</li><li>Multimodal Interaction in Conversational AI</li><li>Natural Language Understanding in Conversational AI</li><li>Case Studies in Speech Processing and Conversational AI</li></ul></td></tr>
<tr><td><strong>Week 5: Transformer Models and Attention Mechanisms</strong><ul><li>Understanding the Transformer Architecture</li><li>Concepts of Self-Attention and Positional Encoding</li><li>Overview of BERT, GPT, and Transformer Variants</li><li>Applications of Transformer Models in NLP</li><li>Training Transformer Models for NLP Tasks</li><li>Challenges and Solutions with Transformer Models</li></ul></td><td><strong>Week 13: Generative AI, Prodcuts, Techniques, APIs and Ethical Considerations</strong><ul><li>Introduction to Generative Models in NLP</li><li>Applications and Challenges of Generative AI</li><li>Ethical Considerations, Data Privacy and Governance in AI</li><li>NLP APIs and Their Practical Uses</li><li>Prompt Engineering for LLMs</li><li>Busineess Intelligence, Marketing, Analytics and Brand Analysis use cases</li><li>Introduction to Product Management and Business Considerations</li></ul></td></tr>
<tr><td><strong>Week 6: Syntax, Parsing, Word Embeddings, and POS Tagging</strong><ul><li>Syntax in Natural Language Processing</li><li>Dependency and Constituency Parsing</li><li>Deep Dive into Word Embeddings</li><li>Word2Vec, GloVe, and FastText Embeddings</li><li>Using Embeddings in NLP Tasks</li><li>Part-of-Speech (POS) Tagging: Importance, Methods, and Tools</li><li>Practical Parsing, Embedding, and POS Tagging Techniques</li><li>Vector Database</li></ul></td><td><strong>Week 14: Fine-Tuning LLMs, Hugging Face, LangChain and RAG</strong><ul><li>Introduction to Fine-Tuning Large Language Models (ChatGPT, Llama etc)</li><li>Overview and Practical Use of Hugging Face in NLP Projects</li><li>Utilizing LangChain and Llama for Customized Language Models</li><li>Best Practices in Fine-Tuning LLMs</li><li>Challenges and Solutions in Fine-Tuning Language Models</li><li>Case Studies and Applications of Fine-Tuned LLMs</li><li>Architecture of Fine-Tuned Models</li></ul></td></tr>
<tr><td><strong>Week 7: Semantic Analysis, Language Models, and Question Answering</strong><ul><li>Semantic Role Labeling (SRL)</li><li>Knowledge Graphs in Semantic Analysis</li><li>Advances in Contextual Embeddings</li><li>Overview of Language Models in NLP </li><li>Introduction to Question Answering System and Utilizing Language Models</li><li>Challenges in QA and Semantic Analysis</li><li>Word Sense Disambiguation Techniques</li></ul></td><td><strong>Week 15: Course Review, Future Trends, and Project Presentations + Final Exam</strong><ul><li>Recap of Key NLP and Generative AI Concepts</li><li>Discussion on the Future Trends in NLP and Generative AI</li><li>Student Project Presentations</li><li>Feedback and Review of Projects</li><li>Resources for Advanced Learning</li><li>Closing Remarks and Course Evaluation</li><ul></td></tr>
<tr><td><strong>Week 8: Text Classification and Machine Translation + Midterm Exam</strong><ul><li>Fundamentals of Text Classification</li><li>Techniques and Algorithms for Classification</li><li>Introduction to Machine Translation</li><li>Neural Machine Translation (NMT) models</li><li>Challenges and Evaluation Metrics for MT</li><li>Practical Implementation of MT Systems</li></ul></td></tr>
    </table>
        <h2>Technological Proficiency</h2>
    <p>Familiarity with Google Colab and Python is necessary. If you havenâ€™t used them, familiarize yourself with Google Colab and set it up. We will teach you the rest of the python packages in the classroom.<br>
       <a href="https://colab.research.google.com/">Google Colab</a></p>
</div>
</body>
</html>
