
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ITP-459 Generative AI and Applied Machine Learning for Natural Language Processing (NLP)</title>
    <style>
        body {
            font-family: 'SF Hello', sans-serif;
        }
        table {
            width: 30%;
            border-collapse: collapse;
        }
        th, td {
            border: 8px solid black;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h1>ITP-459 Applied Machine Learning for Natural Language Processing and Generative AI</h1>
    <h2>University of Southern California (USC), Viterbi School of Engineering </h2>
    <p><strong>Units:</strong>4, <strong>Term:</strong> Spring 2024, <strong>Prerequisite(s):</strong> ITP 359<br>
       <strong>Time:</strong> Mondays 6-9:20 PM, <strong>Location:</strong> KAP 144</p>
    <h2>Instructor Information</h2>
    <p><strong>Instructor:</strong> <a href="https://www.linkedin.com/in/allenbolourchi/">Allen Bolourchi</a><br><br>
       <strong>Office:</strong> Zoom<br>
       <strong>Office Hours:</strong> Tuesdays 6 PM-8 PM by appointment only. Select your desired time 12 hours in advance.</p>
    <h2>Course Assistants</h2>
    <table>
        <tr>
            <th>Course Assistant</th>
            <th>Mode</th>
            <th>Location</th>
            <th>Day</th>
            <th>Time Slot</th>
        </tr>
        <tr>
            <td>Gaurav Tadkapally</td>
            <td>In Person + Online</td>
            <td>TBD</td>
            <td>Monday</td>
            <td>11:00am - 12:00pm</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>Online</td>
            <td>Google Meet</td>
            <td>Thursday</td>
            <td>02:00pm - 03:00pm</td>
        </tr>
        <tr>
            <td>Rajeev Singh</td>
            <td>In Person + Online</td>
            <td>TBD</td>
            <td>Friday</td>
            <td>12:30pm - 01:30pm</td>
        </tr>
    </table>
    <h2>Course Description</h2>
    <p>Learn the state-of-the-art technology in Artificial Intelligence including the latest AI tools and algorithms in Natural Language Processing, Generative AI, GPT/BERT models, and Hugging Face. You will learn the fundamentals of how computers understand human languages and what technologies and products have been built based on NLP and Generative AI for text.</p>
    <h2>Technological Proficiency</h2>
    <p>Familiarity with Google Colab and Python is necessary. If you havenâ€™t used them, familiarize yourself with Google Colab and set it up. We will teach you the rest of the python packages in the classroom.<br>
       <a href="https://colab.research.google.com/">Google Colab</a>></p>
    <h2>Course Schedule: A Weekly Breakdown</h2>
    <table>
        <tr>
            <th>Week</th>
            <th>Topics and Details</th>
        </tr>
<tr><td>Week 1</td><td><strong>Lecture 1: Introduction to NLP and AI</strong><ul><li>Definition and Scope of NLP</li><li>Historical Evolution of AI and NLP</li><li>Key Concepts in Machine Learning and AI</li><li>Overview of NLP Applications in Various Domains</li><li>Basic Text Processing and Language Understanding</li><li>Challenges and Limitations in NLP</li></ul></td></tr>
<tr><td>Week 2</td><td><strong>Lecture 2: Text Cleaning and Preprocessing</strong><ul><li>Importance of Data Cleaning in NLP</li><li>Techniques for Noise Reduction</li><li>Text Normalization and Tokenization</li><li>Lemmatization and Stemming</li><li>Introduction to Co-occurrence Matrix in Text Analysis</li><li>Feature Extraction from Text</li><li>Regular Expressions in Text Processing</li><li>Basic Overview of Word Embeddings</li><li>Overview of relevant python libraries like NLTK, Spacy, regex etc. </li></ul></td></tr>
<tr><td>Week 3</td><td><strong>Lecture 3: Fundamentals of Machine Learning for NLP</strong><ul><li>Introduction to Supervised Learning</li><li>Overview of Unsupervised Learning</li><li>Key ML Algorithms for NLP</li><li>Evaluation Metrics for NLP Models</li><li>Training, Validation, and Test Sets in Model Development</li><li>Overfitting and Underfitting in NLP</li><li>Cross-Validation Techniques</li><li>Introduction to Python ML Libraries</li></ul></td></tr>
<tr><td>Week 4</td><td><strong>Lecture 4: Neural Networks and Deep Learning in NLP</strong><ul><li>Basic Concepts of Neural Networks</li><li>Types of Neural Networks in NLP</li><li>Introduction to Deep Learning</li><li>Activation Functions and Network Topologies</li><li>Backpropagation and Gradient Descent</li><li>Introduction to CNNs and RNNs</li><li>Advanced RNNs: LSTM and GRU</li><li>Sequence Modeling in NLP</li><li>Challenges in Deep Learning for NLP</li><li>Case Studies in Deep Learning for NLP</li></ul></td></tr>
<tr><td>Week 5</td><td><strong>Lecture 5: Transformer Models and Attention Mechanisms</strong><ul><li>Understanding the Transformer Architecture</li><li>Concepts of Self-Attention and Positional Encoding</li><li>Overview of BERT, GPT, and Transformer Variants</li><li>Applications of Transformer Models in NLP</li><li>Training Transformer Models for NLP Tasks</li><li>Challenges and Solutions with Transformer Models</li><li>Week 6: Syntax, Parsing, Word Embeddings, and POS Tagging</li><li>Syntax in Natural Language Processing</li><li>Dependency and Constituency Parsing</li><li>Deep Dive into Word Embeddings</li><li>Word2Vec, GloVe, and FastText Embeddings</li><li>Using Embeddings in NLP Tasks</li><li>Part-of-Speech (POS) Tagging: Importance, Methods, and Tools</li><li>Practical Parsing, Embedding, and POS Tagging Techniques</li><li>Applications of Syntax, Parsing, and POS Tagging in NLP</li><li>Vector Database</li></ul></td></tr>
<tr><td>Week 6</td><td><strong>Lecture 6: Syntax, Parsing, Word Embeddings, and POS Tagging</strong><ul><li>Syntax in Natural Language Processing</li><li>Dependency and Constituency Parsing</li><li>Deep Dive into Word Embeddings</li><li>Word2Vec, GloVe, and FastText Embeddings</li><li>Using Embeddings in NLP Tasks</li><li>Part-of-Speech (POS) Tagging: Importance, Methods, and Tools</li><li>Practical Parsing, Embedding, and POS Tagging Techniques</li><li>Applications of Syntax, Parsing, and POS Tagging in NLP</li><li>Vector Database</li></ul></td></tr>
<tr><td>Week 7</td><td><strong>Lecture 7: Semantic Analysis, Language Models, and Question Answering</strong><ul><li>Semantic Role Labeling (SRL)</li><li>Knowledge Graphs in Semantic Analysis</li><li>Advances in Contextual Embeddings</li><li>Overview of Language Models in NLP </li><li>Introduction to Question Answering System</li><li>Utilizing Language Models in QA</li><li>Challenges in QA </li><li>Challenges in Semantic Analysis</li><li>Word Sense Disambiguation Techniques</li></ul></td></tr>
<tr><td>Week 8</td><td><strong>Lecture 8: Text Classification and Machine Translation + Midterm Exam</strong><ul><li>Fundamentals of Text Classification</li><li>Techniques and Algorithms for Classification</li><li>Introduction to Machine Translation</li><li>Neural Machine Translation (NMT) models</li><li>Challenges and Evaluation Metrics for MT</li><li>Practical Implementation of MT Systems</li></ul></td></tr>
<tr><td>Week 9</td><td><strong>Lecture 9: Advanced Topics in Machine Learning and NLP</strong><ul><li>Deep Transfer Learning in NLP</li><li>Strategies for Addressing Data Imbalance</li><li>Model Interpretability and Explainability in NLP</li><li>Advanced Optimization Techniques in NLP</li><li>Utilizing Pre-Trained NLP Models</li><li>Challenges in Integrating ML and NLP</li><li>Case Studies of Advanced ML in NLP</li><li>Retrieval-Augmented Generation</li></ul></td></tr>
<tr><td>Week 10</td><td><strong>Lecture 10: Named Entity Recognition, Information Retrieval and Search</strong><ul><li>Advanced Techniques in NER</li><li>Contextual NER and Its Applications</li><li>Fundamentals of Information Retrieval</li><li>Deep Dive into TF-IDF and Co-occurrence Matrix</li><li>Search Engines and Indexing Techniques</li><li>Evaluation Metrics in Information Retrieval</li><li>Practical Implementations of NER and IR</li><li>Case Studies and Real-World Applications</li></ul></td></tr>
<tr><td>Week 11</td><td><strong>Lecture 11: Advanced Machine Translation and Summarization</strong><ul><li>Advanced Techniques in Machine Translation</li><li>Handling Low-Resource Languages in (Machine Tranlsation) MT</li><li>Introduction to Text Summarization</li><li>Extractive vs. Abstractive Summarization</li><li>Challenges in Summarization</li><li>Evaluation of Summarization Techniques</li><li>Current Trends in MT and Summarization</li></ul></td></tr>
<tr><td>Week 12</td><td><strong>Lecture 12: Speech Processing and Conversational AI</strong><ul><li>Basics of Speech Recognition</li><li>Challenges in Automatic Speech Recognition (ASR)</li><li>Design and Development of Conversational Agents</li><li>Evaluating Dialogue Systems in Conversational AI</li><li>Multimodal Interaction in Conversational AI</li><li>Natural Language Understanding in Conversational AI</li><li>Case Studies in Speech Processing and Conversational AI</li></ul></td></tr>
<tr><td>Week 13</td><td><strong>Lecture 13: Generative AI, Ethical Considerations, and NLP APIs</strong><ul><li>Introduction to Generative Models in NLP</li><li>Applications and Challenges of Generative AI</li><li>Ethical Considerations, Data Privacy and Governance in AI</li><li>NLP APIs and Their Practical Uses</li><li>Prompt Engineering for LLMs</li><li>Busineess Intelligence, Marketing, Analytics and Brand Analysis use cases</li><li>(Allen to provide) Introduction to Product Management and Business considerations</li></ul></td></tr>
<tr><td>Week 14</td><td><strong>Lecture 14: Fine-Tuning LLMs, Hugging Face, LangChain</strong><ul><li>Introduction to Fine-Tuning Large Language Models (ChatGPT, Llama etc)</li><li>Overview and Practical Use of Hugging Face in NLP Projects</li><li>Utilizing LangChain and Llama for Customized Language Models</li><li>Best Practices in Fine-Tuning LLMs</li><li>Challenges and Solutions in Fine-Tuning Language Models</li><li>Case Studies and Applications of Fine-Tuned LLMs</li><li>Architecture of Fine-Tuned model</li></ul></td></tr>
<tr><td>Week 15</td><td><strong>Lecture 15: Course Review, Future Trends, and Project Presentations + Final Exam</strong><ul><li>Recap of Key NLP and Generative AI Concepts</li><li>Discussion on the Future Trends in NLP and Generative AI</li><li>Student Project Presentations</li><li>Feedback and Review of Projects</li><li>Resources for Advanced Learning</li><li>Closing Remarks and Course Evaluation</li>
        </ul>
        </td>
        </tr>
    </table>
    <p>Note: One Homework is optional! Only top 13 scores of assignments will be considered.</p>
    <p><strong>H*:</strong> National Holiday â€“ No in person class. Watch the recordings.<br>
       <strong>E**:</strong> Exam Day</p>
</body>
</html>
